{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m44\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,114</span> (4.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,114\u001b[0m (4.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,114</span> (4.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,114\u001b[0m (4.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2860 - loss: 1.4482\n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2937 - loss: 1.4336 - val_accuracy: 0.4204 - val_loss: 1.3034\n",
      "Epoch 2/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3964 - loss: 1.2889 \n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3977 - loss: 1.2798 - val_accuracy: 0.5680 - val_loss: 1.1789\n",
      "Epoch 3/1000\n",
      "\u001b[1m18/27\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4313 - loss: 1.2076 \n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4397 - loss: 1.1940 - val_accuracy: 0.6409 - val_loss: 1.0670\n",
      "Epoch 4/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4767 - loss: 1.1201 \n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4824 - loss: 1.1120 - val_accuracy: 0.7120 - val_loss: 0.9643\n",
      "Epoch 5/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 1.0386 \n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5325 - loss: 1.0326 - val_accuracy: 0.7511 - val_loss: 0.8787\n",
      "Epoch 6/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5572 - loss: 0.9934 \n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5584 - loss: 0.9907 - val_accuracy: 0.7991 - val_loss: 0.8080\n",
      "Epoch 7/1000\n",
      "\u001b[1m18/27\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5781 - loss: 0.9630 \n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5805 - loss: 0.9551 - val_accuracy: 0.8000 - val_loss: 0.7453\n",
      "Epoch 8/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.8943 \n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6165 - loss: 0.8938 - val_accuracy: 0.8338 - val_loss: 0.6957\n",
      "Epoch 9/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6268 - loss: 0.8729 \n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6291 - loss: 0.8703 - val_accuracy: 0.8533 - val_loss: 0.6472\n",
      "Epoch 10/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.8218 \n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6731 - loss: 0.8195 - val_accuracy: 0.8560 - val_loss: 0.6092\n",
      "Epoch 11/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6648 - loss: 0.8114 \n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6681 - loss: 0.8101 - val_accuracy: 0.8693 - val_loss: 0.5753\n",
      "Epoch 12/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.7905 \n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6846 - loss: 0.7924 - val_accuracy: 0.8773 - val_loss: 0.5541\n",
      "Epoch 13/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6710 - loss: 0.7854 \n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6766 - loss: 0.7821 - val_accuracy: 0.8871 - val_loss: 0.5223\n",
      "Epoch 14/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.7647 \n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6836 - loss: 0.7582 - val_accuracy: 0.8996 - val_loss: 0.5044\n",
      "Epoch 15/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7095 - loss: 0.7318 \n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7074 - loss: 0.7354 - val_accuracy: 0.9076 - val_loss: 0.4805\n",
      "Epoch 16/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7223 - loss: 0.7187 \n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7210 - loss: 0.7176 - val_accuracy: 0.9120 - val_loss: 0.4707\n",
      "Epoch 17/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.6974 \n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7222 - loss: 0.7003 - val_accuracy: 0.9182 - val_loss: 0.4492\n",
      "Epoch 18/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.6627 \n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7504 - loss: 0.6678 - val_accuracy: 0.9262 - val_loss: 0.4362\n",
      "Epoch 19/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.6781 \n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7337 - loss: 0.6772 - val_accuracy: 0.9342 - val_loss: 0.4198\n",
      "Epoch 20/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.6561 \n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7382 - loss: 0.6527 - val_accuracy: 0.9333 - val_loss: 0.4010\n",
      "Epoch 21/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.6122 \n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7633 - loss: 0.6174 - val_accuracy: 0.9422 - val_loss: 0.3901\n",
      "Epoch 22/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7510 - loss: 0.6362 \n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7522 - loss: 0.6350 - val_accuracy: 0.9413 - val_loss: 0.3762\n",
      "Epoch 23/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.6609 \n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7447 - loss: 0.6526 - val_accuracy: 0.9404 - val_loss: 0.3740\n",
      "Epoch 24/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.6021 \n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7754 - loss: 0.6073 - val_accuracy: 0.9378 - val_loss: 0.3662\n",
      "Epoch 25/1000\n",
      "\u001b[1m17/27\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7623 - loss: 0.6484 \n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7634 - loss: 0.6425 - val_accuracy: 0.9431 - val_loss: 0.3577\n",
      "Epoch 26/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.6180 \n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.6175 - val_accuracy: 0.9404 - val_loss: 0.3507\n",
      "Epoch 27/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 0.5911 \n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7713 - loss: 0.5957 - val_accuracy: 0.9422 - val_loss: 0.3405\n",
      "Epoch 28/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.5998 \n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7786 - loss: 0.5979 - val_accuracy: 0.9458 - val_loss: 0.3358\n",
      "Epoch 29/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.5957 \n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7722 - loss: 0.5913 - val_accuracy: 0.9458 - val_loss: 0.3302\n",
      "Epoch 30/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.5878 \n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7713 - loss: 0.5871 - val_accuracy: 0.9404 - val_loss: 0.3247\n",
      "Epoch 31/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.5646 \n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7893 - loss: 0.5703 - val_accuracy: 0.9511 - val_loss: 0.3146\n",
      "Epoch 32/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.5484 \n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7974 - loss: 0.5549 - val_accuracy: 0.9484 - val_loss: 0.3121\n",
      "Epoch 33/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.5950 \n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7724 - loss: 0.5917 - val_accuracy: 0.9458 - val_loss: 0.3096\n",
      "Epoch 34/1000\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.5836 \n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7903 - loss: 0.5810 - val_accuracy: 0.9467 - val_loss: 0.3065\n",
      "Epoch 35/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.5607 \n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7943 - loss: 0.5597 - val_accuracy: 0.9449 - val_loss: 0.3006\n",
      "Epoch 36/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.5634 \n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7835 - loss: 0.5627 - val_accuracy: 0.9440 - val_loss: 0.2975\n",
      "Epoch 37/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.5763 \n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7794 - loss: 0.5741 - val_accuracy: 0.9458 - val_loss: 0.2966\n",
      "Epoch 38/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.5559 \n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8025 - loss: 0.5558 - val_accuracy: 0.9413 - val_loss: 0.2944\n",
      "Epoch 39/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.5740 \n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7971 - loss: 0.5642 - val_accuracy: 0.9493 - val_loss: 0.2860\n",
      "Epoch 40/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.5148 \n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8133 - loss: 0.5230 - val_accuracy: 0.9467 - val_loss: 0.2862\n",
      "Epoch 41/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8009 - loss: 0.5299 \n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7999 - loss: 0.5332 - val_accuracy: 0.9538 - val_loss: 0.2803\n",
      "Epoch 42/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.5189 \n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8122 - loss: 0.5209 - val_accuracy: 0.9413 - val_loss: 0.2802\n",
      "Epoch 43/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.5599 \n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7936 - loss: 0.5573 - val_accuracy: 0.9404 - val_loss: 0.2789\n",
      "Epoch 44/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5313 \n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8087 - loss: 0.5301 - val_accuracy: 0.9484 - val_loss: 0.2772\n",
      "Epoch 45/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.5428 \n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7996 - loss: 0.5402 - val_accuracy: 0.9440 - val_loss: 0.2735\n",
      "Epoch 46/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.5306 \n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8017 - loss: 0.5295 - val_accuracy: 0.9476 - val_loss: 0.2668\n",
      "Epoch 47/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.5109 \n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8099 - loss: 0.5135 - val_accuracy: 0.9342 - val_loss: 0.2768\n",
      "Epoch 48/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.5026 \n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8218 - loss: 0.5049 - val_accuracy: 0.9467 - val_loss: 0.2661\n",
      "Epoch 49/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.5248 \n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7993 - loss: 0.5258 - val_accuracy: 0.9387 - val_loss: 0.2680\n",
      "Epoch 50/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.5011 \n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8186 - loss: 0.4998 - val_accuracy: 0.9493 - val_loss: 0.2609\n",
      "Epoch 51/1000\n",
      "\u001b[1m18/27\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.5037 \n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8199 - loss: 0.5020 - val_accuracy: 0.9440 - val_loss: 0.2605\n",
      "Epoch 52/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.5319 \n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7947 - loss: 0.5296 - val_accuracy: 0.9511 - val_loss: 0.2572\n",
      "Epoch 53/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.5217 \n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8042 - loss: 0.5172 - val_accuracy: 0.9484 - val_loss: 0.2600\n",
      "Epoch 54/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.5540 \n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7916 - loss: 0.5458 - val_accuracy: 0.9440 - val_loss: 0.2593\n",
      "Epoch 55/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.4749 \n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8241 - loss: 0.4781 - val_accuracy: 0.9458 - val_loss: 0.2553\n",
      "Epoch 56/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5055 \n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7993 - loss: 0.5020 - val_accuracy: 0.9484 - val_loss: 0.2544\n",
      "Epoch 57/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.4772 \n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8243 - loss: 0.4798 - val_accuracy: 0.9467 - val_loss: 0.2488\n",
      "Epoch 58/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.4740 \n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8228 - loss: 0.4779 - val_accuracy: 0.9511 - val_loss: 0.2473\n",
      "Epoch 59/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4799 \n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8166 - loss: 0.4800 - val_accuracy: 0.9422 - val_loss: 0.2515\n",
      "Epoch 60/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4910 \n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8127 - loss: 0.4896 - val_accuracy: 0.9502 - val_loss: 0.2453\n",
      "Epoch 61/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8275 - loss: 0.4722 \n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8257 - loss: 0.4784 - val_accuracy: 0.9547 - val_loss: 0.2422\n",
      "Epoch 62/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.5020 \n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8200 - loss: 0.4997 - val_accuracy: 0.9493 - val_loss: 0.2430\n",
      "Epoch 63/1000\n",
      "\u001b[1m18/27\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5396 \n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8039 - loss: 0.5275 - val_accuracy: 0.9431 - val_loss: 0.2491\n",
      "Epoch 64/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.4940 \n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8209 - loss: 0.4914 - val_accuracy: 0.9467 - val_loss: 0.2468\n",
      "Epoch 65/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4685 \n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8279 - loss: 0.4698 - val_accuracy: 0.9484 - val_loss: 0.2436\n",
      "Epoch 66/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.4794 \n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8183 - loss: 0.4803 - val_accuracy: 0.9529 - val_loss: 0.2384\n",
      "Epoch 67/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.4715 \n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8363 - loss: 0.4711 - val_accuracy: 0.9556 - val_loss: 0.2409\n",
      "Epoch 68/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4656 \n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.4676 - val_accuracy: 0.9378 - val_loss: 0.2539\n",
      "Epoch 69/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.5074 \n",
      "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8210 - loss: 0.5026 - val_accuracy: 0.9547 - val_loss: 0.2390\n",
      "Epoch 70/1000\n",
      "\u001b[1m17/27\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8129 - loss: 0.4876 \n",
      "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8172 - loss: 0.4816 - val_accuracy: 0.9502 - val_loss: 0.2426\n",
      "Epoch 71/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.4540 \n",
      "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8354 - loss: 0.4536 - val_accuracy: 0.9511 - val_loss: 0.2368\n",
      "Epoch 72/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4706 \n",
      "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8233 - loss: 0.4719 - val_accuracy: 0.9360 - val_loss: 0.2418\n",
      "Epoch 73/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4633 \n",
      "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8387 - loss: 0.4650 - val_accuracy: 0.9582 - val_loss: 0.2322\n",
      "Epoch 74/1000\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4613 \n",
      "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8329 - loss: 0.4599 - val_accuracy: 0.9493 - val_loss: 0.2342\n",
      "Epoch 75/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.4490 \n",
      "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8409 - loss: 0.4506 - val_accuracy: 0.9529 - val_loss: 0.2364\n",
      "Epoch 76/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8317 - loss: 0.4523 \n",
      "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8300 - loss: 0.4550 - val_accuracy: 0.9422 - val_loss: 0.2419\n",
      "Epoch 77/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4537 \n",
      "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8303 - loss: 0.4559 - val_accuracy: 0.9520 - val_loss: 0.2375\n",
      "Epoch 78/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4701 \n",
      "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8384 - loss: 0.4683 - val_accuracy: 0.9484 - val_loss: 0.2355\n",
      "Epoch 79/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4730 \n",
      "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8257 - loss: 0.4705 - val_accuracy: 0.9538 - val_loss: 0.2346\n",
      "Epoch 80/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.4463 \n",
      "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8439 - loss: 0.4474 - val_accuracy: 0.9467 - val_loss: 0.2453\n",
      "Epoch 81/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.4382 \n",
      "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8363 - loss: 0.4414 - val_accuracy: 0.9520 - val_loss: 0.2331\n",
      "Epoch 82/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.4643 \n",
      "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8295 - loss: 0.4645 - val_accuracy: 0.9520 - val_loss: 0.2366\n",
      "Epoch 83/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.4465 \n",
      "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8305 - loss: 0.4481 - val_accuracy: 0.9484 - val_loss: 0.2376\n",
      "Epoch 84/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.4355 \n",
      "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8418 - loss: 0.4358 - val_accuracy: 0.9431 - val_loss: 0.2393\n",
      "Epoch 85/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.4463 \n",
      "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8384 - loss: 0.4486 - val_accuracy: 0.9511 - val_loss: 0.2325\n",
      "Epoch 86/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4475 \n",
      "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8323 - loss: 0.4493 - val_accuracy: 0.9431 - val_loss: 0.2445\n",
      "Epoch 87/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.4633 \n",
      "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8344 - loss: 0.4598 - val_accuracy: 0.9502 - val_loss: 0.2370\n",
      "Epoch 88/1000\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.4609 \n",
      "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8390 - loss: 0.4597 - val_accuracy: 0.9467 - val_loss: 0.2434\n",
      "Epoch 89/1000\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4781 \n",
      "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8246 - loss: 0.4792 - val_accuracy: 0.9440 - val_loss: 0.2470\n",
      "Epoch 90/1000\n",
      "\u001b[1m17/27\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.4588 \n",
      "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8389 - loss: 0.4538 - val_accuracy: 0.9520 - val_loss: 0.2394\n",
      "Epoch 91/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.4897 \n",
      "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8306 - loss: 0.4822 - val_accuracy: 0.9458 - val_loss: 0.2419\n",
      "Epoch 92/1000\n",
      "\u001b[1m17/27\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4510 \n",
      "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8461 - loss: 0.4466 - val_accuracy: 0.9431 - val_loss: 0.2409\n",
      "Epoch 93/1000\n",
      "\u001b[1m19/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.4370 \n",
      "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8387 - loss: 0.4402 - val_accuracy: 0.9449 - val_loss: 0.2361\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29b4133d610>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9417 - loss: 0.2450 \n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "[0.8116126  0.09184989 0.05241374 0.04412381]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in .\\.venv\\lib\\site-packages (2.2.3)\n",
      "Collecting seaborn\n",
      "  Obtaining dependency information for seaborn from https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl.metadata\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: matplotlib in .\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in .\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in .\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in .\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas seaborn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.10      0.16       407\n",
      "           1       0.40      0.08      0.14       388\n",
      "           2       0.22      0.10      0.14       317\n",
      "           3       0.02      1.00      0.03        13\n",
      "\n",
      "    accuracy                           0.10      1125\n",
      "   macro avg       0.26      0.32      0.12      1125\n",
      "weighted avg       0.34      0.10      0.14      1125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ketan\\AppData\\Local\\Temp\\tmpqonigphz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ketan\\AppData\\Local\\Temp\\tmpqonigphz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\ketan\\AppData\\Local\\Temp\\tmpqonigphz'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='keras_tensor_54')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2865884699856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2865884698320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2865884698512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2865884696784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2865884698704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2865884700624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6072"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python_pro\\hand-gesture-recognition-using-mediapipe-main\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 7.47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21177374 0.23035762 0.2444782  0.31339046]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
